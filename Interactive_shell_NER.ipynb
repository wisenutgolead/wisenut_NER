{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T05:20:50.621420Z",
     "start_time": "2017-11-20T05:20:49.619093Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import argparse\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from data_utils import Vocabulary\n",
    "from data_utils import load_data_interactive\n",
    "\n",
    "from data_loader import prepare_sequence, prepare_char_sequence, prepare_lex_sequence\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from CNN_BiLSTM import CNNBiLSTM\n",
    "from data_loader import get_loader\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T05:20:50.633905Z",
     "start_time": "2017-11-20T05:20:50.623178Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_path='./data_in/vocab_ko_NER.pkl'\n",
    "char_vocab_path='./data_in/char_vocab_ko_NER.pkl'\n",
    "pos_vocab_path='./data_in/pos_vocab_ko_NER.pkl'\n",
    "lex_dict_path='./data_in/lex_dict.pkl'\n",
    "model_load_path='./data_in/cnn_bilstm_tagger-179-400_f1_0.8739_maxf1_0.8739_100_200_2.pkl'\n",
    "num_layers=2\n",
    "embed_size=100\n",
    "hidden_size=200 \n",
    "gpu_index=0\n",
    "\n",
    "predict_NER_dict = {0: '<PAD>',\n",
    "                    1: '<START>',\n",
    "                    2: '<STOP>',\n",
    "                    3: 'B_LC',\n",
    "                    4: 'B_DT',\n",
    "                    5: 'B_OG',\n",
    "                    6: 'B_TI',\n",
    "                    7: 'B_PS',\n",
    "                    8: 'I',\n",
    "                    9: 'O'}\n",
    "\n",
    "NER_idx_dic = {'<unk>': 0, 'LC': 1, 'DT': 2, 'OG': 3, 'TI': 4, 'PS': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T05:20:50.648788Z",
     "start_time": "2017-11-20T05:20:50.638012Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_np(x):\n",
    "    return x.data.cpu().numpy()\n",
    "\n",
    "def to_var(x, volatile=False):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda(gpu_index)\n",
    "    return Variable(x, volatile=volatile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T05:20:51.914303Z",
     "start_time": "2017-11-20T05:20:51.027562Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# apply word2vec\n",
    "from gensim.models import word2vec\n",
    "pretrained_word2vec_file = './data_in/word2vec/ko_word2vec_' + str(embed_size) + '.model'\n",
    "wv_model_ko = word2vec.Word2Vec.load(pretrained_word2vec_file)\n",
    "word2vec_matrix = wv_model_ko.wv.syn0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T05:20:51.971027Z",
     "start_time": "2017-11-20T05:20:51.916650Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab):  28386\n",
      "word2vec_matrix:  (28386, 100)\n"
     ]
    }
   ],
   "source": [
    "# build vocab\n",
    "with open(vocab_path, 'rb') as f:\n",
    "    vocab = pickle.load(f)\n",
    "print(\"len(vocab): \",len(vocab))\n",
    "print(\"word2vec_matrix: \",np.shape(word2vec_matrix))\n",
    "with open(char_vocab_path, 'rb') as f:\n",
    "    char_vocab = pickle.load(f)\n",
    "with open(pos_vocab_path, 'rb') as f:\n",
    "    pos_vocab = pickle.load(f)\n",
    "with open(lex_dict_path, 'rb') as f:\n",
    "    lex_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T05:20:52.700063Z",
     "start_time": "2017-11-20T05:20:52.018458Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build models\n",
    "cnn_bilstm_tagger = CNNBiLSTM(vocab_size=len(vocab),\n",
    "                                     char_vocab_size=len(char_vocab),\n",
    "                                        pos_vocab_size=len(pos_vocab),\n",
    "                                        lex_ner_size=len(NER_idx_dic),\n",
    "                                        embed_size=embed_size,\n",
    "                                        hidden_size=hidden_size,\n",
    "                                        num_layers=num_layers,\n",
    "                                        word2vec=word2vec_matrix,\n",
    "                                        num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T05:20:52.834806Z",
     "start_time": "2017-11-20T05:20:52.708097Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If you don't use GPU, you can get error here (in the case of loading state dict from Tensor on GPU)\n",
    "#  To avoid error, you should use options -> map_location=lambda storage, loc: storage. it will load tensor to CPU\n",
    "cnn_bilstm_tagger.load_state_dict(torch.load(model_load_path, map_location=lambda storage, loc: storage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T05:20:53.685881Z",
     "start_time": "2017-11-20T05:20:53.563893Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    cnn_bilstm_tagger.cuda(gpu_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T05:20:54.360263Z",
     "start_time": "2017-11-20T05:20:54.342784Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNBiLSTM (\n",
       "  (embed): Embedding(28386, 100, padding_idx=0)\n",
       "  (trainable_embed): Embedding(28386, 100, padding_idx=0)\n",
       "  (lstm): LSTM(818, 200, num_layers=2, batch_first=True, dropout=0.6, bidirectional=True)\n",
       "  (char_embed): Embedding(2284, 100, padding_idx=0)\n",
       "  (pos_embed): Embedding(232, 100, padding_idx=0)\n",
       "  (convs1): ModuleList (\n",
       "    (0): Conv2d(1, 128, kernel_size=(2, 100), stride=(1, 1))\n",
       "    (1): Conv2d(1, 128, kernel_size=(3, 100), stride=(1, 1))\n",
       "    (2): Conv2d(1, 128, kernel_size=(4, 100), stride=(1, 1))\n",
       "    (3): Conv2d(1, 128, kernel_size=(5, 100), stride=(1, 1))\n",
       "  )\n",
       "  (dropout): Dropout (p = 0.5)\n",
       "  (fc1): Linear (400 -> 10)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inference mode\n",
    "cnn_bilstm_tagger.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T05:20:56.747225Z",
     "start_time": "2017-11-20T05:20:55.514519Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocessing(x_text_batch, x_pos_batch, x_split_batch):\n",
    "    x_text_char_item = []\n",
    "    for x_word in x_text_batch[0]:\n",
    "        x_char_item = []\n",
    "        for x_char in x_word:\n",
    "            x_char_item.append(x_char)\n",
    "        x_text_char_item.append(x_char_item)\n",
    "    x_text_char_batch = [x_text_char_item]\n",
    "\n",
    "    x_idx_item = prepare_sequence(x_text_batch[0], vocab.word2idx)\n",
    "    x_idx_char_item = prepare_char_sequence(x_text_char_batch[0], char_vocab.word2idx)\n",
    "    x_pos_item = prepare_sequence(x_pos_batch[0], pos_vocab.word2idx)\n",
    "    x_lex_item = prepare_lex_sequence(x_text_batch[0], lex_dict)\n",
    "\n",
    "    x_idx_batch = [x_idx_item]\n",
    "    x_idx_char_batch = [x_idx_char_item]\n",
    "    x_pos_batch = [x_pos_item]\n",
    "    x_lex_batch = [x_lex_item]\n",
    "\n",
    "\n",
    "    max_word_len = int(np.amax([len(word_tokens) for word_tokens in x_idx_batch])) # ToDo: usually, np.mean can be applied\n",
    "    batch_size = len(x_idx_batch)\n",
    "    batch_words_len = [len(word_tokens) for word_tokens in x_idx_batch]\n",
    "    batch_words_len = np.array(batch_words_len)\n",
    "\n",
    "    # Padding procedure (word)\n",
    "    padded_word_tokens_matrix = np.zeros((batch_size, max_word_len), dtype=np.int64)\n",
    "    for i in range(padded_word_tokens_matrix.shape[0]):\n",
    "        for j in range(padded_word_tokens_matrix.shape[1]):\n",
    "            try:\n",
    "                padded_word_tokens_matrix[i, j] = x_idx_batch[i][j]\n",
    "            except IndexError:\n",
    "                pass\n",
    "\n",
    "    max_char_len = int(np.amax([len(char_tokens) for word_tokens in x_idx_char_batch for char_tokens in word_tokens]))\n",
    "    if max_char_len < 5: # size of maximum filter of CNN\n",
    "        max_char_len = 5\n",
    "        \n",
    "    # Padding procedure (char)\n",
    "    padded_char_tokens_matrix = np.zeros((batch_size, max_word_len, max_char_len), dtype=np.int64)\n",
    "    for i in range(padded_char_tokens_matrix.shape[0]):\n",
    "        for j in range(padded_char_tokens_matrix.shape[1]):\n",
    "            for k in range(padded_char_tokens_matrix.shape[1]):\n",
    "                try:\n",
    "                    padded_char_tokens_matrix[i, j, k] = x_idx_char_batch[i][j][k]\n",
    "                except IndexError:\n",
    "                    pass\n",
    "\n",
    "    # Padding procedure (pos)\n",
    "    padded_pos_tokens_matrix = np.zeros((batch_size, max_word_len), dtype=np.int64)\n",
    "    for i in range(padded_pos_tokens_matrix.shape[0]):\n",
    "        for j in range(padded_pos_tokens_matrix.shape[1]):\n",
    "            try:\n",
    "                padded_pos_tokens_matrix[i, j] = x_pos_batch[i][j]\n",
    "            except IndexError:\n",
    "                pass\n",
    "\n",
    "    # Padding procedure (lex)\n",
    "    padded_lex_tokens_matrix = np.zeros((batch_size, max_word_len, len(NER_idx_dic)))\n",
    "    for i in range(padded_lex_tokens_matrix.shape[0]):\n",
    "        for j in range(padded_lex_tokens_matrix.shape[1]):\n",
    "            for k in range(padded_lex_tokens_matrix.shape[2]):\n",
    "                try:\n",
    "                    for x_lex in x_lex_batch[i][j]:\n",
    "                        k = NER_idx_dic[x_lex]\n",
    "                        padded_lex_tokens_matrix[i, j, k] = 1\n",
    "                except IndexError:\n",
    "                    pass\n",
    "\n",
    "                \n",
    "    x_text_batch = x_text_batch\n",
    "    x_split_batch = x_split_batch\n",
    "    padded_word_tokens_matrix = torch.from_numpy(padded_word_tokens_matrix)\n",
    "    padded_char_tokens_matrix = torch.from_numpy(padded_char_tokens_matrix)\n",
    "    padded_pos_tokens_matrix = torch.from_numpy(padded_pos_tokens_matrix)\n",
    "    padded_lex_tokens_matrix = torch.from_numpy(padded_lex_tokens_matrix).float()\n",
    "    lengths = batch_words_len\n",
    "\n",
    "    return x_text_batch, x_split_batch, padded_word_tokens_matrix, padded_char_tokens_matrix, padded_pos_tokens_matrix, padded_lex_tokens_matrix, lengths\n",
    "\n",
    "def parsing_seq2NER(argmax_predictions, x_text_batch):\n",
    "    predict_NER_list = []\n",
    "    predict_text_NER_result_batch = copy.deepcopy(x_text_batch[0]) #tuple ([],) -> return first list (batch_size == 1)\n",
    "    for argmax_prediction_seq in argmax_predictions:\n",
    "        predict_NER = []\n",
    "        NER_B_flag = None # stop B\n",
    "        prev_NER_token = None\n",
    "        for i, argmax_prediction in enumerate(argmax_prediction_seq):\n",
    "                now_NER_token = predict_NER_dict[argmax_prediction.cpu().data.numpy()[0]]\n",
    "                predict_NER.append(now_NER_token)\n",
    "                if now_NER_token in ['B_LC', 'B_DT', 'B_OG', 'B_TI', 'B_PS'] and NER_B_flag is None: # O B_LC\n",
    "                    NER_B_flag = now_NER_token # start B\n",
    "                    predict_text_NER_result_batch[i] = '<'+predict_text_NER_result_batch[i]\n",
    "                    prev_NER_token = now_NER_token\n",
    "                    if i == len(argmax_prediction_seq)-1:\n",
    "                        predict_text_NER_result_batch[i] = predict_text_NER_result_batch[i]+':'+now_NER_token[-2:]+'>'\n",
    "\n",
    "                elif now_NER_token in ['B_LC', 'B_DT', 'B_OG', 'B_TI', 'B_PS'] and NER_B_flag is not None: # O B_LC B_DT\n",
    "                    predict_text_NER_result_batch[i-1] = predict_text_NER_result_batch[i-1]+':'+prev_NER_token[-2:]+'>'\n",
    "                    predict_text_NER_result_batch[i] = '<' + predict_text_NER_result_batch[i]\n",
    "                    prev_NER_token = now_NER_token\n",
    "                    if i == len(argmax_prediction_seq)-1:\n",
    "                        predict_text_NER_result_batch[i] = predict_text_NER_result_batch[i]+':'+now_NER_token[-2:]+'>'\n",
    "\n",
    "                elif now_NER_token in ['I'] and NER_B_flag is not None:\n",
    "                    if i == len(argmax_prediction_seq) - 1:\n",
    "                        predict_text_NER_result_batch[i] = predict_text_NER_result_batch[i] + ':' + NER_B_flag[-2:] + '>'\n",
    "\n",
    "                elif now_NER_token in ['O'] and NER_B_flag is not None: # O B_LC I O\n",
    "                    predict_text_NER_result_batch[i-1] = predict_text_NER_result_batch[i-1] + ':' + prev_NER_token[-2:] + '>'\n",
    "                    NER_B_flag = None # stop B\n",
    "                    prev_NER_token = now_NER_token\n",
    "\n",
    "        predict_NER_list.append(predict_NER)\n",
    "    return predict_NER_list, predict_text_NER_result_batch\n",
    "\n",
    "def generate_text_result(text_NER_result_batch, x_split_batch):\n",
    "    prev_x_split = 0 \n",
    "    text_string = ''\n",
    "    for i, x_split in enumerate(x_split_batch[0]):\n",
    "        if prev_x_split != x_split:\n",
    "            text_string = text_string+' '+text_NER_result_batch[i]\n",
    "            prev_x_split = x_split\n",
    "        else:\n",
    "            text_string = text_string +''+ text_NER_result_batch[i]\n",
    "            prev_x_split = x_split\n",
    "    return text_string\n",
    "\n",
    "\n",
    "def NER_print(input_str):\n",
    "    input_str.replace(\"  \", \"\")\n",
    "    input_str = input_str.strip()\n",
    "    \n",
    "    x_text_batch, x_pos_batch, x_split_batch = load_data_interactive(input_str)\n",
    "    x_text_batch, x_split_batch, padded_word_tokens_matrix, padded_char_tokens_matrix, padded_pos_tokens_matrix, padded_lex_tokens_matrix, lengths = preprocessing(x_text_batch, x_pos_batch, x_split_batch)\n",
    "    \n",
    "    # Test\n",
    "    argmax_labels_list = []\n",
    "    argmax_predictions_list = []\n",
    "\n",
    "\n",
    "    padded_word_tokens_matrix = to_var(padded_word_tokens_matrix, volatile=True)\n",
    "    padded_char_tokens_matrix = to_var(padded_char_tokens_matrix, volatile=True)\n",
    "    padded_pos_tokens_matrix = to_var(padded_pos_tokens_matrix, volatile=True)\n",
    "    padded_lex_tokens_matrix = to_var(padded_lex_tokens_matrix, volatile=True)\n",
    "\n",
    "\n",
    "    predictions = cnn_bilstm_tagger.sample(padded_word_tokens_matrix, padded_char_tokens_matrix, padded_pos_tokens_matrix, padded_lex_tokens_matrix, lengths)\n",
    "    \n",
    "    max_predictions, argmax_predictions = predictions.max(2)\n",
    "\n",
    "    if len(argmax_predictions.size()) != len(\n",
    "        predictions.size()):  # Check that class dimension is reduced or not (API version issue, pytorch 0.1.12)\n",
    "        max_predictions, argmax_predictions = predictions.max(2, keepdim=True)\n",
    "\n",
    "    argmax_predictions_list.append(argmax_predictions)\n",
    "    \n",
    "    predict_NER_list, predict_text_NER_result_batch = parsing_seq2NER(argmax_predictions, x_text_batch)\n",
    "\n",
    "\n",
    "#     print(\"x_text: \",x_text_batch)\n",
    "#     print(\"NER_pred: \",predict_NER_list)\n",
    "#     print(\"predict_text_NER_result_batch: \",predict_text_NER_result_batch)\n",
    "#     print(\"x_split_batch: \",x_split_batch)\n",
    "    \n",
    "    \n",
    "    origin_text_string = generate_text_result(x_text_batch[0], x_split_batch)\n",
    "    predict_NER_text_string = generate_text_result(predict_text_NER_result_batch, x_split_batch)\n",
    "\n",
    "\n",
    "#     print(\"origin:  \",origin_text_string)\n",
    "#     print(\"predict: \",predict_NER_text_string)\n",
    "    print(\"output> \",predict_NER_text_string)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T05:29:12.848154Z",
     "start_time": "2017-11-20T05:26:33.859211Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input> 서울 사는 윤주성\n",
      "output>  <서울:LC> 사는 <윤주성:PS>\n",
      "\n",
      "input> 내 이름은 윤주성입니다. 나는 서울에 살고 있습니다. 매일매일 안암동으로 출근합니다.\n",
      "output>  내 이름은 <윤주성:PS>입니다. 나는 <서울:LC>에 살고 있습니다. <매일:DT><매일:DT> <안암동:LC>으로 출근합니다.\n",
      "\n",
      "input> 그러나 美의회에는 베트남·니카라과에서 받은 교훈으로 民主 정치가 강하게 뿌리를 내린 곳이 아니면 군사적 효과가 없다는 분위기가 감돌고 있다.\n",
      "output>  그러나 <美의회:OG>에는 <베트남:LC>·<니카라과:LC>에서 받은 교훈으로 民主 정치가 강하게 뿌리를 내린 곳이 아니면 군사적 효과가 없다는 분위기가 감돌고 있다.\n",
      "\n",
      "input> 8월 말 : 미국 정부, 한국이 스크린쿼터를 없애지 않으면 양국 정상이 6월 합의한 투자협정 약속을 무산시킬 수밖에 없다는 입장을 한국 정부에 통보.\n",
      "output>  <8월 말:DT> : <미국:LC> <정부:OG>, <한국:LC>이 스크린쿼터를 없애지 않으면 양국 정상이 <6월:DT> 합의한 투자협정 약속을 무산시킬 수밖에 없다는 입장을 <한국:LC> <정부:OG>에 통보.\n",
      "\n",
      "input> 지난 해 네이버는 라인 상장과 새로운 경영 리더십 구축을 계기로, 대외 조직의 일하는 방식도 쇄신하며 외부 문의나 요청들을 모두 공식적인 프로세스를 통해 진행하는 시스템을 구축했습니다.\n",
      "output>  <지난 해:DT> <네이버:OG>는 <라인:OG> 상장과 새로운 경영 리더십 구축을 계기로, 대외 조직의 일하는 방식도 쇄신하며 외부 문의나 요청들을 모두 공식적인 프로세스를 통해 진행하는 시스템을 구축했습니다.\n",
      "\n",
      "input> 국내 영화시장 규모는 최근 3년간 2조 원대에서 정체된 상태인 해외 로컬 제작 방식으로 만든 '수상한 그녀'가 중국, 베트남, 일본, 태국 등 5개국 리메이크돼 총 780억 원의 매출로 성공을 거둔 바 있습니다.\n",
      "output>  국내 영화시장 규모는 최근 <3년간:DT> 2조 원대에서 정체된 상태인 해외 로컬 제작 방식으로 만든 '수상한 그녀'가 <중국:LC>, <베트남:LC>, <일본:LC>, <태국:LC> 등 5개국 리메이크돼 총 780억 원의 매출로 성공을 거둔 바 있습니다.\n",
      "\n",
      "input> 도널드 트럼프 미국 대통령이 7일 한국에 도착했다. 취임 후 첫 한국 방문이자, 미국 대통령으로서는 25년 만의 국빈방문이다.\n",
      "output>  <도널드 트럼프:PS> <미국:LC> 대통령이 <7일:DT> <한국:LC>에 도착했다. 취임 후 첫 <한국:LC> 방문이자, <미국:LC> 대통령으로서는 <25년:DT> 만의 국빈방문이다.\n",
      "\n",
      "input> 엔씨소프트는 1997년 3월에 설립되었다. 설립자인 김택진 사장은 개발자 출신의 CEO다. 김 사장은 서울대학교 전자공학과 재학시절 ‘컴퓨터연구회’라는 동아리에서 이찬진 드림위즈 사장 등과 ‘아래아한글’을 공동 개발했다.\n",
      "output>  <엔씨소프트:OG>는 <1997년 3월:DT>에 설립되었다. 설립자인 <김택진:PS> 사장은 개발자 출신의 CEO다. <김:PS> 사장은 <서울대학교:OG> 전자공학과 재학시절 ‘컴퓨터연구회’라는 동아리에서 <이찬진:PS> <드림위즈:OG> 사장 등과 ‘아래아한글’을 공동 개발했다.\n",
      "\n",
      "input> exit\n"
     ]
    }
   ],
   "source": [
    "# 모델성능 f1 87.39\n",
    "while(True):\n",
    "    \n",
    "    input_str = input('input> ')\n",
    "    \n",
    "    if input_str == 'exit':\n",
    "        break\n",
    "    else:\n",
    "        NER_print(input_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
